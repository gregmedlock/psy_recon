{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a roadmap from beginning truth to the final iteration of iPto19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "from cobra import Model, Gene, Reaction, Metabolite\n",
    "from cobra.core.gene import parse_gpr,eval_gpr\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import medusa\n",
    "from medusa.test import load_universal_modelseed\n",
    "import csv\n",
    "import matplotlib.pylab as plt\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V1 was originally created from the feeder document, which was derived from looking at reactions present in the draft reconstruction and confirming the activity and presence of an enzyme. This is the document that starts the whole process. It was converted first into an sbml file format to be later read as a cobra model object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'' is not a valid SBML 'SId'.\n"
     ]
    }
   ],
   "source": [
    "#these are the universal variables \n",
    "seed_draft = cobra.io.load_json_model('../data/modelseed_data/modelseed_draft_psy_DC3000.json')\n",
    "universal = load_universal_modelseed()\n",
    "filepath_model = \"../results/reconstructions/\"\n",
    "filesuff_xml = \".xml\"\n",
    "filesuff_csv = \".csv\"\n",
    "pa = cobra.io.read_sbml_model('../data/previous_reconstructions/iPAE1146_resaved.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring reaction 'rxn00182_c' since it already exists.\n",
      "Ignoring reaction 'rxn00260_c' since it already exists.\n",
      "Ignoring reaction 'rxn00493_c' since it already exists.\n",
      "Ignoring reaction 'rxn00527_c' since it already exists.\n",
      "Ignoring reaction 'rxn01640_c' since it already exists.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>PST</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x01230b6860</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>242</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>149</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of groups</strong></td>\n",
       "                <td>0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td>c, e</td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model PST at 0x1230b6860>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is a general excel script that is used to convert each of the excel files into a json model, which is then converted into an sbml model for ease of access\n",
    "#generate the list of reactions to be used for generating the model, from the curation file\n",
    "pst_feeder_xl_file = pd.read_excel('../data/PST_feeder.xlsx')\n",
    "\n",
    "filevar = \"pst_feeder\"\n",
    "\n",
    "#at this point we have a grab bag of reactions ready to be inserted into the model, which we have yet to create\n",
    "model = Model('PST') #empty model\n",
    "\n",
    "#add reactions from the grab bag\n",
    "for i in range(0,len(pst_feeder_xl_file)):\n",
    "    reaction_row = pst_feeder_xl_file.iloc[i,]\n",
    "    reaction_id = str(reaction_row['Reaction ID'])[:-1]\n",
    "    reaction_to_add = universal.reactions.get_by_id(reaction_id).copy()\n",
    "    # add subsystem for the reaction\n",
    "    reaction_to_add.subsystem = reaction_row ['Subsystems']\n",
    "    # add gpr for the reaction\n",
    "    reaction_to_add.gene_reaction_rule = reaction_row['GPR'] \n",
    "    # set the bounds based on the manual curation we did (rxns in universal are reversible)\n",
    "    # calling .item() is necessary to convert the numpy datatype into a native Python float\n",
    "    # to be compatible with the libsbml parser/writer.\n",
    "    reaction_to_add.bounds = (reaction_row['Lower bound'].item(),\n",
    "                              reaction_row['Upper bound'].item())\n",
    "    model.add_reaction(reaction_to_add)\n",
    "\n",
    "save_dir_model = filepath_model+filevar+filesuff_xml\n",
    "write_dir = filepath_model + filevar + filesuff_csv\n",
    "\n",
    "with open(write_dir, 'w', newline='') as csvfile:\n",
    "    csvfile = csv.writer(csvfile, delimiter=',')\n",
    "    for rxn in model.reactions:\n",
    "        csvfile.writerow([rxn.id, rxn.name, rxn.reaction, rxn.gene_reaction_rule,rxn.lower_bound, rxn.upper_bound])\n",
    "\n",
    "cobra.io.write_sbml_model(model, save_dir_model)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V1 was not integrated with the orthologs between PAO1 and Pst yet. So, there are a few scripts and outputs that achive this. Originally, this was done through the scripts \"ortholog_compiler\", \"comp_list\", \"rxns_left\", \"rxn_list_comp\" all feeding into the newly updated PST_curation.xlsx. I will combine all the scripts here in the next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cobra/core/group.py:109 \u001b[1;31mUserWarning\u001b[0m: need to pass in a list\n"
     ]
    }
   ],
   "source": [
    "filevar = \"PSTv1\"\n",
    "\n",
    "#this is the script originally called \"ortholog_to_list.py\" which was used to compare the PAO1 and PST orthologs to the list of PAO1 gprs in PAO1 reactions\n",
    "#followed by comparing the list of PAO1 reactions to the list of reactions left to be curated in PST draft. If there is an ortholog between PAO1 and PSt, and it has a\n",
    "#matching reaction that is defined in PAO1, the reaction will be added to a list with updated orthologous genes in PST.\n",
    "#read the two library files for the lists, as well as the reaction list to call reactions\n",
    "orthologs = pd.read_csv('../data/previous_data_from_curation/PA01_PSY_orthologs.csv')\n",
    "\n",
    "#first create dictionary with the orthologous pairs\n",
    "ortholog_dict = {}\n",
    "\n",
    "for x in range(0, len(orthologs)):\n",
    "    pair_row = orthologs.iloc[x,]\n",
    "    query = pair_row['Locus Tag (Query)']\n",
    "    result = pair_row['Locus Tag (Hit)']\n",
    "    ortholog_dict[query]=result\n",
    "\n",
    "    \n",
    "# Copy the PAO1 model, since we will be \"using it for parts\" during curation.\n",
    "pa_original = pa.copy()\n",
    "\n",
    "# Now see if each reaction from PAO1 has a satisfied GPR based on\n",
    "# The orthology. Reactions in PAO1 are used for GPR manipulation and\n",
    "# then are added directly to our model.\n",
    "unmapped_rxns = []\n",
    "mapped_rxns = {}\n",
    "for reaction in pa.reactions:\n",
    "    rxn_gpr = reaction.gene_reaction_rule\n",
    "    new_gpr = rxn_gpr\n",
    "    # Search all of the orthologs against the GPR and replace any hits\n",
    "    found_gene = False\n",
    "    for gene in ortholog_dict.keys():\n",
    "        if rxn_gpr.find(gene) > -1:\n",
    "            # replace the ortholog in the new GPR\n",
    "            new_gpr = new_gpr.replace(gene, ortholog_dict[gene])\n",
    "            found_gene = True\n",
    "            if reaction.id in mapped_rxns.keys():\n",
    "                mapped_rxns[reaction.id].append(gene)\n",
    "            else:\n",
    "                mapped_rxns[reaction.id] = [gene]\n",
    "    # If an ortholog was found for any genes in this GPR, see if\n",
    "    # the GPR is functional when we swap out orthologs and \n",
    "    # remove remaining PAO1 genes.\n",
    "    if found_gene:\n",
    "\n",
    "        # convert to the AST structure to perform knockouts on the GPR\n",
    "        as_tree, gene_set = parse_gpr(new_gpr)\n",
    "        # knock out any PAO1 genes in the new GPR and check for functionality\n",
    "        genes_to_ko = []\n",
    "        for gene in reaction.genes:\n",
    "            if gene.id.startswith('PA'):\n",
    "                genes_to_ko.append(gene)\n",
    "        ko_result = eval_gpr(as_tree,set([g.id for g in genes_to_ko]))\n",
    "        # if we were able to knock out all the PAO1 genes and the reaction\n",
    "        # was still functional, then we should remove the PAO1 genes from\n",
    "        # the model and add any PST genes that were in functional reactions.\n",
    "        if ko_result:\n",
    "            reaction.gene_reaction_rule = new_gpr\n",
    "            # remove the gene; don't remove the reaction yet, since we are \n",
    "            # currently iterating over the reactions (removal will cause\n",
    "            # a skip for another reaction)\n",
    "            cobra.manipulation.remove_genes(pa,genes_to_ko,remove_reactions=False)\n",
    "        else: # if the knockout failed, the reaction doesn't fully map\n",
    "            unmapped_rxns.append(reaction.id)\n",
    "            \n",
    "    else:\n",
    "        # if the GPR is the same, the reaction does not map to PST\n",
    "        # and we can remove it from the PAO1 model to simplify\n",
    "        unmapped_rxns.append(reaction.id)\n",
    "        \n",
    "pa.remove_reactions(unmapped_rxns)\n",
    "\n",
    "# Add the reactions remaining in PAO1. If they already exist in PST,\n",
    "# just use the existing GPR. Report conflicts too (e.g., existing\n",
    "# reaction that already has a GPR which differs from the orthology-\n",
    "# based GPR).\n",
    "rxns_to_add = []\n",
    "conflicting_gprs = {}\n",
    "for reaction in pa.reactions:\n",
    "    if reaction.id+'_c' not in [r.id for r in model.reactions]:\n",
    "        to_add = reaction.copy()\n",
    "        to_add.id = to_add.id + '_c'\n",
    "        rxns_to_add.append(to_add)\n",
    "    else:\n",
    "        # We will keep the annotated GPRs in modelSEED for now, but save the information.\n",
    "        conflicting_gprs[reaction.id] = {'orthology-transferred GPR':reaction.gene_reaction_rule,\n",
    "                                        'pst-annotation GPR in SEED':model.reactions.get_by_id(reaction.id+'_c').gene_reaction_rule}\n",
    "        \n",
    "pd.DataFrame(conflicting_gprs).T.to_csv('../results/future_curation/potential_GPR_conflicts.tsv',sep='\\t')\n",
    "model.add_reactions(rxns_to_add)\n",
    "\n",
    "save_dir_model = filepath_model+filevar+filesuff_xml\n",
    "write_dir = filepath_model + filevar + filesuff_csv\n",
    "\n",
    "with open(write_dir, 'w', newline='') as csvfile:\n",
    "    csvfile = csv.writer(csvfile, delimiter=',')\n",
    "    for rxn in model.reactions:\n",
    "        csvfile.writerow([rxn.id, rxn.name, rxn.reaction, rxn.gene_reaction_rule,rxn.lower_bound, rxn.upper_bound])\n",
    "\n",
    "cobra.io.write_sbml_model(model, save_dir_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filevar = \"PSTv2\"\n",
    "#biomass reactions are temporarily added for gapfilling purposes\n",
    "bio1 = seed_draft.reactions.bio1.copy()\n",
    "bio2 = pa_original.reactions.PAO1_Biomass.copy()\n",
    "bio3 = pa_original.reactions.PA_Biomass_v13ub.copy()\n",
    "bio4 = pa_original.reactions.PA_Biomass_v13.copy()\n",
    "bio5 = pa_original.reactions.PA_Biomass_v4.copy()\n",
    "model.add_reactions([bio1, bio2, bio3, bio4, bio5])\n",
    "\n",
    "\n",
    "save_dir_model = filepath_model+filevar+filesuff_xml\n",
    "write_dir = filepath_model + filevar + filesuff_csv\n",
    "\n",
    "with open(write_dir, 'w', newline='') as csvfile:\n",
    "    csvfile = csv.writer(csvfile, delimiter=',')\n",
    "    for rxn in model.reactions:\n",
    "        csvfile.writerow([rxn.id, rxn.name, rxn.reaction, rxn.gene_reaction_rule,rxn.lower_bound, rxn.upper_bound])\n",
    "\n",
    "cobra.io.write_sbml_model(model, save_dir_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get from v2 to v3 is the next step. This is the point where we added a lot of nomenclature for satisfying MEMOTE, including the inchie strings and other database knowledge. We are now integrating these steps after the rest of the curation, but are skipping to generation of v4 to keep our naming consistent with the previous approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring reaction 'rxn02276_c' since it already exists.\n"
     ]
    }
   ],
   "source": [
    "filevar = \"PSTv4_post_ensemble1\"\n",
    "  \n",
    "#for specific information of the inclusion of reactions, including particularites of the evidence, please reference curate_from_ensemble_round1.ipynb        \n",
    "##the following is from the first round of curation that took place, from the original gapfilling through ensemble number 1\n",
    "rxn1 = universal.reactions.get_by_id('rxn02276_c').copy()\n",
    "rxn1.gene_reaction_rule  = ' PSPTO_3554 '\n",
    "rxn1.notes = {'ensemble_curation_step':1}\n",
    "rxn2 = universal.reactions.get_by_id('rxn09072_c').copy()\n",
    "rxn2.gene_reaction_rule = ' PSPTO_4214 '\n",
    "rxn2.notes = {'ensemble_curation_step':1}\n",
    "rxn3 = universal.reactions.get_by_id('rxn00993_c').copy()\n",
    "rxn3.gene_reaction_rule = ' PSPTO_5292 '\n",
    "rxn3.notes = {'ensemble_curation_step':1}\n",
    "rxn4 = universal.reactions.get_by_id('rxn10878_c').copy()\n",
    "rxn4.gene_reaction_rule = ' PSPTO_2510 '\n",
    "rxn4.notes = {'ensemble_curation_step':1}\n",
    "rxn5 = universal.reactions.get_by_id('rxn01418_c').copy()\n",
    "rxn5.gene_reaction_rule = ' (PSPTO_2199 and PSPTO_2200 and PSPTO_2201) '\n",
    "rxn5.notes = {'ensemble_curation_step':1}\n",
    "model.add_reactions([rxn1, rxn2, rxn3, rxn4, rxn5])\n",
    "\n",
    "save_dir_model = filepath_model+filevar+filesuff_xml\n",
    "write_dir = filepath_model + filevar + filesuff_csv\n",
    "\n",
    "with open(write_dir, 'w', newline='') as csvfile:\n",
    "    csvfile = csv.writer(csvfile, delimiter=',')\n",
    "    for rxn in model.reactions:\n",
    "        csvfile.writerow([rxn.id, rxn.name, rxn.reaction, rxn.gene_reaction_rule,rxn.lower_bound, rxn.upper_bound])\n",
    "\n",
    "cobra.io.write_sbml_model(model, save_dir_model)\n",
    "\n",
    "\n",
    "#now create the ensemble, round two after the first set of curation was added to the base model\n",
    "filevar = \"PSTv4_post_ensemble2\"\n",
    "\n",
    "##the following is from the second round of ensemble gapfilling\n",
    "rxn1 = universal.reactions.get_by_id('rxn01423_c').copy()\n",
    "rxn1.gene_reaction_rule  = 'PSPTO_4775 or PSPTO_5504 or PSPTO_0096'\n",
    "rxn1.notes = {'ensemble_curation_step':2}\n",
    "rxn2 = universal.reactions.get_by_id('rxn03005_c').copy()\n",
    "rxn2.gene_reaction_rule  = 'PSPTO_1468 or PSPTO_1699'\n",
    "rxn2.notes = {'ensemble_curation_step':2}\n",
    "rxn3 = universal.reactions.get_by_id('rxn00688_c').copy()\n",
    "rxn3.gene_reaction_rule  = 'PSPTO_1468 or PSPTO_1699 or PSPTO_4866 or PSPTO_0178'\n",
    "rxn3.notes = {'ensemble_curation_step':2}\n",
    "rxn4 = universal.reactions.get_by_id('rxn01211_c').copy()\n",
    "rxn4.gene_reaction_rule  = 'PSPTO_2453'\n",
    "rxn4.notes = {'ensemble_curation_step':2}\n",
    "rxn5 = universal.reactions.get_by_id('rxn00835_c').copy()\n",
    "rxn5.gene_reaction_rule  = 'PSPTO_2022 and PSPTO_1131'\n",
    "rxn5.notes = {'ensemble_curation_step':2}\n",
    "rxn6 = universal.reactions.get_by_id('rxn05316_c').copy()\n",
    "rxn6.gene_reaction_rule  = 'Unknown'\n",
    "rxn6.notes = {'ensemble_curation_step':2}\n",
    "rxn7 = universal.reactions.get_by_id('rxn13150_c').copy()\n",
    "rxn7.gene_reaction_rule  = 'PSPTO_2453 and PSPTO_3733 and PSPTO_5069'\n",
    "rxn7.notes = {'ensemble_curation_step':2}\n",
    "rxn8 = universal.reactions.get_by_id('rxn10036_c').copy()\n",
    "rxn8.gene_reaction_rule  = 'PSPTO_3503 and PSPTO_5530'\n",
    "rxn8.notes = {'ensemble_curation_step':2}\n",
    "\n",
    "#these reactions also came from the second ensemble, but were specifically focusing on arginine metabolism\n",
    "rxn9 = universal.reactions.get_by_id('rxn05303_c').copy()\n",
    "rxn9.gene_reactions_rule = 'Unknown'\n",
    "rxn9.notes = {'ensemble_curation_step':2}\n",
    "rxn10 = universal.reactions.get_by_id('rxn00245_c').copy()\n",
    "rxn10.gene_reaction_rule = '(PSPTO_2662)'\n",
    "rxn10.notes = {'ensemble_curation_step' :2}\n",
    "rxn11 = universal.reactions.get_by_id('rxn01934_c').copy()\n",
    "rxn11.gene_reaction_rule = '(PSPTO_2424 or PSPTO_2434 or PSPTO_3287 or PSPTO_3460 or PSPTO_3920)'\n",
    "rxn11.notes = {'ensemble_curation_step' :2}\n",
    "rxn12 = universal.reactions.get_by_id('rxn01827_c').copy()\n",
    "rxn12.gene_reaction_rule = '(PSPTO_2346)'\n",
    "rxn12.notes = {'ensemble_curation_step' :2}\n",
    "model.add_reactions([rxn1, rxn2, rxn3, rxn4, rxn5, rxn6, rxn7, rxn8, rxn9, rxn10, rxn11, rxn12])\n",
    "\n",
    "\n",
    "save_dir_model = filepath_model+filevar+filesuff_xml\n",
    "write_dir = filepath_model + filevar + filesuff_csv\n",
    "\n",
    "with open(write_dir, 'w', newline='') as csvfile:\n",
    "    csvfile = csv.writer(csvfile, delimiter=',')\n",
    "    for rxn in model.reactions:\n",
    "        csvfile.writerow([rxn.id, rxn.name, rxn.reaction, rxn.gene_reaction_rule,rxn.lower_bound, rxn.upper_bound])\n",
    "\n",
    "cobra.io.write_sbml_model(model, save_dir_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After PSTv4 with all annotations added, first round of ensemble gapfilling took place, where we created an ensemble of 500 members, gapfilled to the biolog growth data, and looked for the most disparate reaction additions in alternative gapfilling solutions for curation.\n",
    "After the first round was complete, we ended up with model_post_ensemble_curation_round1.xml. This was followed with a second wave of ensemble curation, with changes made to the base model to fill in the curated reactions, and another 500 member ensemble was created. Again the most disperate reactions were found within the solutions, and these were targeted for curation.\n",
    "The framework of execution can be in the file \"gapfill_to_ensemble.ipynb\", which takes any clear positive growth on biolog data (>0.3OD) and creates an exchange reaction for the substrate. Gapfilling solutions are generated based on this script, where the number of ensemble members can be changed to generate ensembles of different sizes. The framework presented in the example script was used for each ensemble curation step. The next script, ensemble_learning.ipynb is to generate the list of the most disperate reactions, and finally, the output is an excel file with all of the reactions in their disperate form. From this, the script curate_from_ensemble***.ipynb is used as a journal for reaction additions or deletions to the model from the base model of the ensemble.\n",
    "There is a drastic reduction in the number of metabolites and the number of reactions due to cleaning up exchange reactions and the previous biomass reactions as well.\n",
    "The exchange reactions were introduced from the information in the Ma and Mhadmi papers, respectivly https://doi.org/10.1073/pnas.1319485111 and https://doi.org/10.1016/j.envexpbot.2014.07.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From PSTv5 to PSTv6, the main changes include integrating exchange reactions from the Anderson 2014 paper, which looked at the differences in apoplasmic content of arabidopsis in normal and mkp1 mutants. This information is later used as in planta simulations for ensemble gene deletions. This is done in the notebook new_exchange_rxns2.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addition of the LPS pathway following, for more information on the inclusion of this pathway, please reference lps_curation.ipynb\n",
    "filevar = 'PSTv5'\n",
    "\n",
    "#lpxa = universal.reactions.rxn06729_c.copy()\n",
    "#lpxa.gene_reaciton_rule = (\"PSPTO_1546\")\n",
    "lpxc = universal.reactions.rxn03146_c.copy()\n",
    "lpxc.gene_reaction_rule = (\"PSPTO_4402\")\n",
    "#lpxd = universal.reactions.rxn06723_c.copy()\n",
    "#lpxd.gene_reaction_rule = (\"PSPTO_1542\")\n",
    "lpxh = universal.reactions.rxn03130_c.copy()\n",
    "lpxh.gene_reaction_rule = (\"PSPTO_3745\")\n",
    "lpxb1 = universal.reactions.rxn03159_c.copy()\n",
    "lpxb1.gene_reaction_rule = (\"PSPTO_1547\")\n",
    "lpxb2 = universal.reactions.rxn03181_c.copy()\n",
    "lpxb2.gene_reaction_rule = (\"PSPTO_1547\")\n",
    "kdta1 = universal.reactions.rxn03182_c.copy()\n",
    "kdta1.gene_reaction_rule = (\"PSPTO_4978\")\n",
    "kdta2 = universal.reactions.rxn03439_c.copy()\n",
    "kdta2.gene_reaction_rule = (\"PSPTO_4978\")\n",
    "htrb = universal.reactions.rxn06848_c.copy()\n",
    "htrb.gene_reaction_rule = (\"PSPTO_3871\")\n",
    "\n",
    "model.add_reactions([ lpxc, lpxh,lpxb1,lpxb2,kdta1,kdta2,htrb])\n",
    "\n",
    "save_dir_model = filepath_model+filevar+filesuff_xml\n",
    "write_dir = filepath_model + filevar + filesuff_csv\n",
    "\n",
    "with open(write_dir, 'w', newline='') as csvfile:\n",
    "    csvfile = csv.writer(csvfile, delimiter=',')\n",
    "    for rxn in model.reactions:\n",
    "        csvfile.writerow([rxn.id, rxn.name, rxn.reaction, rxn.gene_reaction_rule,rxn.lower_bound, rxn.upper_bound])\n",
    "\n",
    "cobra.io.write_sbml_model(model, save_dir_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSTv6 integrated the exchange reactions in an improper form, and this rendered them to not be marked as exchange reactions. To fix this, I added _e to the metabolite identifiers at the end of the exchange reactions in the original script of new_exchange_rxns2.ipynb. Further additions to PSTv6 include the LPS synthesis pathway. The two notebooks necessary for these changes are new_exchange_rxns2.ipynb and lps_ciration.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next major addition was the coronatine synthesis pathway, which was performed in cor_addition.ipynb and now presented here. This went two ways: the first attempt was to add each of the reactions independantly that were laid out in https://doi.org/10.1073/pnas.95.26.15469 . This is a putative pathway, but the most worked out one to date. However due to issues of mass balance in ACP, I collapsed the pathway to more reflect the basic syntehsis posed in Pseudomonas syringae Phytotoxins: Mode of Action, Regulation, and Biosynthesis by Peptide and Polyketide Synthetases (no doi presented)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filevar = 'PSTv6'\n",
    "\n",
    "cor1 = Metabolite(\n",
    "    'cpd16565_c',\n",
    "    formula='C18H24NO4',\n",
    "    name='Coronatine',\n",
    "    compartment='c')\n",
    "cor2 = Metabolite(\n",
    "    'cpd16565_e',\n",
    "    formula='C18H24NO4',\n",
    "    name='Coronatine',\n",
    "    compartment='e')\n",
    "\n",
    "cpd00211_c = universal.metabolites.cpd00211_c.copy()\n",
    "\n",
    "rxn1 = Reaction('cor_synth')\n",
    "rxn1.name = 'Coronatine Synthesis'\n",
    "rxn1.lower_bound = 0\n",
    "rxn1.upper_bound = 1000\n",
    "rxn1.gene_reaction_rule = ('PSPTO_0259 or PSPTO_0301 and PSPTO_4709 and PSPTO_4680 or PSPTO_4685 and PSPTO_4681 or PSPTO_4683 and PSPTO_4682 and PSPTO_4690 and PSPTO_4686 and PSPTO_4687')\n",
    "rxn1.add_metabolites({model.metabolites.cpd00322_c: -1,\n",
    "                     model.metabolites.cpd00029_c : -3,\n",
    "                     cpd00211_c : -1,\n",
    "                     model.metabolites.cpd00020_c : -1,\n",
    "                     model.metabolites.cpd00011_c : 3,\n",
    "                     model.metabolites.cpd00067_c : 2,\n",
    "                     model.metabolites.cpd00001_c : 3,\n",
    "                     cor1 : 1})\n",
    "rxn2 = Reaction('cor_trans')\n",
    "rxn2.name = 'Coronatine Transport'\n",
    "rxn2.lower_bound = 0\n",
    "rxn2.upper_bound = 1000\n",
    "rxn2.add_metabolites({cor1 : -1,\n",
    "                      cor2 : 1})\n",
    "rxn3 = Reaction('EX_cpd16565_e')\n",
    "rxn3.name = 'Coronatine Exchange'\n",
    "rxn3.lower_bound = 0\n",
    "rxn3.upper_bound = 1000\n",
    "rxn3.add_metabolites({cor2: -1})\n",
    "\n",
    "model.add_reactions ([rxn1, rxn2,rxn3])\n",
    "\n",
    "save_dir_model = filepath_model+filevar+filesuff_xml\n",
    "write_dir = filepath_model + filevar + filesuff_csv\n",
    "\n",
    "with open(write_dir, 'w', newline='') as csvfile:\n",
    "    csvfile = csv.writer(csvfile, delimiter=',')\n",
    "    for rxn in model.reactions:\n",
    "        csvfile.writerow([rxn.id, rxn.name, rxn.reaction, rxn.gene_reaction_rule,rxn.lower_bound, rxn.upper_bound])\n",
    "\n",
    "cobra.io.write_sbml_model(model, save_dir_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To PSTv6, the next major change was the addition of the PST specific biomass equation, generating PSTv7. This is done through the notebook concise_gapfill.ipynb, which is a part of the gapfilling protocol. So, even though it is embedded in the gapfilling protocol, this will not change the outcome bcause it is drawing from the same source everytime. There is no additional model based with the actual biomass equation, however, using the adapted version of the gapfilling protocol, I have generated PSTv7 with the new biomass equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filevar = \"PSTv7\"\n",
    "df = pd.read_csv(\"../data/bio1_biomass_adapted.csv\")\n",
    "for metabolite in model.reactions.bio1.metabolites:\n",
    "    model.reactions.bio1.subtract_metabolites({metabolite : model.reactions.bio1.get_coefficient(metabolite.id)})\n",
    "for row in df.itertuples():\n",
    "    try:\n",
    "        model.metabolites.get_by_id(row.id)\n",
    "    except:\n",
    "        if row.id in universal.metabolites:\n",
    "            met_to_add = universal.metabolites.get_by_id(row.id)\n",
    "            model.add_metabolites([met_to_add])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "for row in df.itertuples():\n",
    "    model.reactions.bio1.add_metabolites({model.metabolites.get_by_id(row.id) : row.coefficient})\n",
    "\n",
    "#remove the previous temporary biomass equations:\n",
    "model.remove_reactions(['PAO1_Biomass', 'PA_Biomass_v13ub', 'PA_Biomass_v13', 'PA_Biomass_v4'], remove_orphans = True)\n",
    "\n",
    "#write to a model and a cav file of the version\n",
    "save_dir_model = filepath_model+filevar+filesuff_xml\n",
    "write_dir = filepath_model + filevar + filesuff_csv\n",
    "\n",
    "with open(write_dir, 'w', newline='') as csvfile:\n",
    "    csvfile = csv.writer(csvfile, delimiter=',')\n",
    "    for rxn in model.reactions:\n",
    "        csvfile.writerow([rxn.id, rxn.name, rxn.reaction, rxn.gene_reaction_rule,rxn.lower_bound, rxn.upper_bound])\n",
    "\n",
    "cobra.io.write_sbml_model(model, save_dir_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSTv7 underwent another gapfilling protocol to have one more final curation step, in which all the added reactions were queried for potential additional gprs to add to the given reactions. This was done in the notebook gpr_filler.ipynb, aptly named.\n",
    "The resulting base model is named PSTv8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring reaction 'rxn00541_c' since it already exists.\n",
      "Ignoring reaction 'rxn00726_c' since it already exists.\n",
      "Ignoring reaction 'rxn00727_c' since it already exists.\n",
      "Ignoring reaction 'rxn03393_c' since it already exists.\n",
      "Ignoring reaction 'rxn05607_c' since it already exists.\n",
      "Ignoring reaction 'rxn03005_c' since it already exists.\n",
      "Ignoring reaction 'rxn05303_c' since it already exists.\n",
      "Ignoring reaction 'rxn00506_c' since it already exists.\n",
      "Ignoring reaction 'rxn01388_c' since it already exists.\n",
      "Ignoring reaction 'rxn01418_c' since it already exists.\n",
      "Ignoring reaction 'rxn01827_c' since it already exists.\n",
      "Ignoring reaction 'rxn00101_c' since it already exists.\n",
      "Ignoring reaction 'rxn01211_c' since it already exists.\n",
      "Ignoring reaction 'rxn00623_c' since it already exists.\n",
      "Ignoring reaction 'rxn05183_c' since it already exists.\n",
      "Ignoring reaction 'rxn02186_c' since it already exists.\n",
      "Ignoring reaction 'rxn05289_c' since it already exists.\n",
      "Ignoring reaction 'rxn00328_c' since it already exists.\n",
      "Ignoring reaction 'rxn00917_c' since it already exists.\n",
      "Ignoring reaction 'rxn10206_c' since it already exists.\n",
      "Ignoring reaction 'rxn10221_c' since it already exists.\n",
      "Ignoring reaction 'rxn00962_c' since it already exists.\n",
      "Ignoring reaction 'rxn09167_c' since it already exists.\n",
      "Ignoring reaction 'rxn13834_c' since it already exists.\n",
      "Ignoring reaction 'rxn00993_c' since it already exists.\n",
      "Ignoring reaction 'rxn02276_c' since it already exists.\n",
      "Ignoring reaction 'rxn03513_c' since it already exists.\n",
      "Ignoring reaction 'rxn09997_c' since it already exists.\n",
      "Ignoring reaction 'rxn00898_c' since it already exists.\n",
      "Ignoring reaction 'rxn08291_c' since it already exists.\n",
      "Ignoring reaction 'rxn13150_c' since it already exists.\n",
      "Ignoring reaction 'rxn00853_c' since it already exists.\n",
      "Ignoring reaction 'rxn05215_c' since it already exists.\n",
      "Ignoring reaction 'rxn00342_c' since it already exists.\n",
      "Ignoring reaction 'rxn09072_c' since it already exists.\n",
      "Ignoring reaction 'rxn03004_c' since it already exists.\n",
      "Ignoring reaction 'rxn01225_c' since it already exists.\n",
      "Ignoring reaction 'rxn00711_c' since it already exists.\n",
      "Ignoring reaction 'rxn00691_c' since it already exists.\n",
      "Ignoring reaction 'rxn02483_c' since it already exists.\n",
      "Ignoring reaction 'rxn00980_c' since it already exists.\n",
      "Ignoring reaction 'rxn08975_c' since it already exists.\n"
     ]
    }
   ],
   "source": [
    "filevar = 'PSTv8'\n",
    "with open(\"../results/ensembles/pto_ensemble_100_updated102519.pickle\", 'rb') as infile:\n",
    "    ensemble = load(infile)\n",
    "    \n",
    "#modify the gprs to include the manually annotated gene:reactions pairs from KEGG and BLASTing\n",
    "missing_gprs_df = pd.read_excel('../data/gene_annotations/gpr_kegg_missing_reactions.xlsx', columns = ['rxn_id', 'gpr'])\n",
    "rxn_gpr_dict = {}\n",
    "for idx, row in missing_gprs_df.iterrows():\n",
    "    rxn_gpr_dict[row[0] + '_c'] = row[1]\n",
    "    \n",
    "\n",
    "for rxn,gpr in rxn_gpr_dict.items():\n",
    "    if rxn in str(ensemble.base_model.reactions):\n",
    "        if \"Unknown\" in gpr:\n",
    "            pass\n",
    "        else: \n",
    "            rxn_to_add = ensemble.base_model.reactions.get_by_id(rxn).copy()\n",
    "            rxn_to_add.gene_reaction_rule = gpr\n",
    "            model.add_reaction(rxn_to_add)\n",
    "\n",
    "gene_associations = pd.read_excel('../results/gene_associations_to_add.xlsx')\n",
    "association_dict = {}\n",
    "for x in gene_associations.itertuples():\n",
    "    association_dict[x.rxn[0:10]] = x.gene\n",
    "for key, val in association_dict.items():\n",
    "    if key in ensemble.base_model.reactions:\n",
    "        rxn_to_add = ensemble.base_model.reactions.get_by_id(key).copy()\n",
    "        rxn_to_add.gene_reaction_rule = val\n",
    "        model.add_reaction(rxn_to_add)\n",
    "        \n",
    "#add reactions that are positivly annotated in the draft, and already have a matching gene reaction rule that fits the reaction annotated in the draft recon\n",
    "missing_rxns = pd.read_excel(\"../data/missing_reactions_draft_v_v8.xlsx\")\n",
    "gprs_to_add_to_v8 = {}\n",
    "for row in missing_rxns.itertuples():\n",
    "    if row.evidence == 1:\n",
    "        gprs_to_add_to_v8[row.id] = row.gpr\n",
    "for key,value in gprs_to_add_to_v8.items():\n",
    "    try:\n",
    "        rxn_to_add = universal.reactions.get_by_id(key).copy()\n",
    "        rxn_to_add.gene_reaction_rule = value\n",
    "        model.add_reactions([rxn_to_add])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "save_dir_model = filepath_model+filevar+filesuff_xml\n",
    "write_dir = filepath_model + filevar + filesuff_csv\n",
    "\n",
    "with open(write_dir, 'w', newline='') as csvfile:\n",
    "    csvfile = csv.writer(csvfile, delimiter=',')\n",
    "    for rxn in model.reactions:\n",
    "        csvfile.writerow([rxn.id, rxn.name, rxn.reaction, rxn.gene_reaction_rule,rxn.lower_bound, rxn.upper_bound])\n",
    "\n",
    "# Some reactions from the universal seem to have a '<' or '>' character that libSBML does not like.\n",
    "# rewrite those notes here so we can save as SBML.\n",
    "for reaction in model.reactions:\n",
    "    if 'gapfill_data' in reaction.notes.keys():\n",
    "        reaction.notes['gapfill_data'] = 'modelseed gapfill with new PST annotation'\n",
    "\n",
    "cobra.io.write_sbml_model(model, save_dir_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSTv8 can now undergo a final gapfilling step using the ensemble method to simulated growth on media and other analysis presented in this paper. See final_ensemble_gapfill.ipynb for this step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "driven_devel",
   "language": "python",
   "name": "driven_devel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
